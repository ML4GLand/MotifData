{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import glob\n",
    "import numpy as np\n",
    "import motifdata as md\n",
    "from pkg_resources import resource_filename\n",
    "from eugene import models\n",
    "from eugene import settings\n",
    "settings.logging_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/revision/jores21\"\n",
    "settings.config_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/configs/jores21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_motif_set(motif_set):\n",
    "    print(f\"# motifs: {len(motif_set)}\")\n",
    "    print(f\"Alphabet: {motif_set.alphabet}\")\n",
    "    print(f\"Version: {motif_set.version}\")\n",
    "    print(f\"Strands: {motif_set.strands}\")\n",
    "    print(f\"Background: {motif_set.background}\")\n",
    "    print(f\"Background source: {motif_set.background_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_motifs(motif_set, n=None):\n",
    "    for motif in motif_set:\n",
    "        print(f\"Identifer: {motif.identifier}\")\n",
    "        print(f\"Name: {motif.name}\")\n",
    "        print(f\"Consensus: {motif.consensus}\")\n",
    "        print(f\"PFM: {motif.pfm} with shape {motif.pfm.shape}\")\n",
    "        print()\n",
    "        if n is not None:\n",
    "            n -= 1\n",
    "            if n == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_available_layers(\n",
    "    model: nn.Module,\n",
    "    key_word = None\n",
    ") -> list:\n",
    "    \"\"\"List the available layers in a model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The model to list the layers of\n",
    "    key_word : str, optional\n",
    "        A key word to filter the layers by, by default None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of the available layers in the model\n",
    "    \"\"\"\n",
    "    layers = sorted([k for k in dict([*model.named_modules()])])\n",
    "    if key_word is not None:\n",
    "        layers = [layer for layer in layers if key_word in layer]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer(\n",
    "    model: nn.Module,\n",
    "    layer_name: str\n",
    ") -> nn.Module:\n",
    "    \"\"\"Get a layer from a model by name. Note that this will only work for\n",
    "    named modules. If the model has unnamed modules, TODO\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The model to get the layer from\n",
    "    layer_name : str\n",
    "        The name of the layer to get\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.nn.Module\n",
    "        The layer from the model\n",
    "    \"\"\"\n",
    "    return dict([*model.named_modules()])[layer_name]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a kernel to MEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 3\n"
     ]
    }
   ],
   "source": [
    "leaf_model_file = glob.glob(os.path.join(settings.logging_dir, \"cnn\", \"leaf_trial_3\", \"checkpoints\", \"*\"))[0]\n",
    "model = models.load_config(config_path=\"cnn.yaml\")\n",
    "leaf_model = models.SequenceModule.load_from_checkpoint(leaf_model_file, arch=model.arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arch.conv1d_tower',\n",
       " 'arch.conv1d_tower.layers',\n",
       " 'arch.conv1d_tower.layers.0',\n",
       " 'arch.conv1d_tower.layers.1',\n",
       " 'arch.conv1d_tower.layers.10',\n",
       " 'arch.conv1d_tower.layers.11',\n",
       " 'arch.conv1d_tower.layers.12',\n",
       " 'arch.conv1d_tower.layers.13',\n",
       " 'arch.conv1d_tower.layers.14',\n",
       " 'arch.conv1d_tower.layers.2',\n",
       " 'arch.conv1d_tower.layers.3',\n",
       " 'arch.conv1d_tower.layers.4',\n",
       " 'arch.conv1d_tower.layers.5',\n",
       " 'arch.conv1d_tower.layers.6',\n",
       " 'arch.conv1d_tower.layers.7',\n",
       " 'arch.conv1d_tower.layers.8',\n",
       " 'arch.conv1d_tower.layers.9']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_available_layers(leaf_model, key_word=\"conv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first convolutional layer and set kernels < 0 to 0\n",
    "layer = get_layer(leaf_model, \"arch.conv1d_tower.layers.0\")\n",
    "kernels = layer.weight.data.numpy()\n",
    "kernels[kernels < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# motifs: 256\n",
      "Alphabet: ACGT\n",
      "Version: 5\n",
      "Strands: + -\n",
      "Background: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "Background source: None\n",
      "\n",
      "Identifer: filter_0\n",
      "Name: filter_0\n",
      "Consensus: TCTCTATAAATAC\n",
      "PFM: [[0.3872321  1.4875679  0.4326479  1.5474236 ]\n",
      " [0.5810361  1.6907147  0.6329294  0.92154586]\n",
      " [0.92491764 1.0179404  0.8485242  1.0865945 ]\n",
      " [0.541581   2.6780574  0.23881885 0.3438842 ]\n",
      " [0.         0.         0.02326916 4.0359554 ]\n",
      " [3.8641582  0.         0.         0.12367285]\n",
      " [0.         0.         0.         4.0058208 ]\n",
      " [3.9876742  0.         0.06564526 0.        ]\n",
      " [2.4759955  0.         0.10032247 1.3471979 ]\n",
      " [3.86505    0.         0.06999157 0.        ]\n",
      " [1.2255843  0.07950763 0.13378221 2.3990386 ]\n",
      " [2.8052242  0.22689693 0.4605895  0.36558354]\n",
      " [0.40350372 1.7106136  1.2255125  0.5111682 ]] with shape (13, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "motif_set = md.from_kernel(kernels, bg = {\"A\": 0.25, \"C\": 0.25, \"G\": 0.25, \"T\": 0.25})\n",
    "describe_motif_set(motif_set)\n",
    "print()\n",
    "print_motifs(motif_set, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pfm in MEME format as: /cellar/users/aklie/projects/ML4GLand/MotifData/motifdata/resources/filters_out.meme\n"
     ]
    }
   ],
   "source": [
    "md.write_meme(motif_set, resource_filename('motifdata', 'resources/filters_out.meme'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MotifSet into model kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# motifs: 72\n",
      "Alphabet: ACGT\n",
      "Version: 5\n",
      "Strands: + -\n",
      "Background: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "Background source: None\n",
      "\n",
      "Identifer: TF-cluster_1\n",
      "Name: NAC\n",
      "Consensus: TTACGTGTAGAACAAG\n",
      "PFM: [[0.1949128  0.01640289 0.00895095 0.7797334 ]\n",
      " [0.2782767  0.00825623 0.2022142  0.511253  ]\n",
      " [0.4608514  0.1265213  0.3093912  0.1032361 ]\n",
      " [0.02296122 0.9709426  0.001743   0.00435315]\n",
      " [0.00325958 0.01182932 0.5375714  0.4473397 ]\n",
      " [0.00417949 0.00398073 0.01938412 0.9724556 ]\n",
      " [0.2775764  0.06676622 0.6315887  0.02406878]\n",
      " [0.2904112  0.186561   0.1394217  0.383606  ]\n",
      " [0.3518847  0.1558543  0.246462   0.245799  ]\n",
      " [0.2788753  0.1914388  0.3083355  0.2213506 ]\n",
      " [0.3565019  0.2176151  0.1845846  0.2412985 ]\n",
      " [0.4840646  0.09719634 0.1803039  0.2384354 ]\n",
      " [0.06016895 0.5575891  0.2264818  0.1557602 ]\n",
      " [0.944828   0.01806365 0.00485082 0.03225751]\n",
      " [0.6672574  0.2912842  0.02046174 0.02099667]\n",
      " [0.01196582 0.00227141 0.9621388  0.02362408]] with shape (16, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#motif_set = md.read_homer(resource_filename('motifdata', 'resources/sample.motifs'))\n",
    "#motif_set = md.read_meme(\"/cellar/users/aklie/data/ml4gland/use_cases/jores21/paper_github/CPEs.meme\")\n",
    "motif_set = md.read_meme(\"/cellar/users/aklie/data/ml4gland/use_cases/jores21/paper_github/TF-clusters.meme\")\n",
    "describe_motif_set(motif_set)\n",
    "print()\n",
    "print_motifs(motif_set, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.12173441, -0.08135366,  0.05647704, -0.0386282 ],\n",
       "        [-0.02299144,  0.01623187,  0.11310549,  0.0295976 ],\n",
       "        [ 0.09796639, -0.06018299, -0.01161144, -0.01280014],\n",
       "        [-0.00947437, -0.10643078,  0.0982954 , -0.06520253],\n",
       "        [ 0.0076355 , -0.11207107,  0.01673558, -0.12620355],\n",
       "        [-0.0472234 ,  0.01564597,  0.08229609, -0.1126551 ],\n",
       "        [-0.1283058 , -0.0463211 ,  0.10362144,  0.06945334],\n",
       "        [ 0.11920424, -0.07438475,  0.12470192,  0.00858062],\n",
       "        [-0.12152293,  0.1052118 ,  0.03757446, -0.02479482],\n",
       "        [ 0.00618484, -0.00333846,  0.01732013,  0.03577886],\n",
       "        [ 0.02141361,  0.11727677,  0.04337198, -0.03345665],\n",
       "        [-0.03767323,  0.08713868, -0.07901561, -0.13641895],\n",
       "        [ 0.0264579 ,  0.12546062,  0.10012502,  0.1140984 ]],\n",
       "       dtype=float32),\n",
       " array([[ 1.21734411e-01, -8.13536569e-02,  5.64770401e-02,\n",
       "         -3.86282019e-02],\n",
       "        [-2.29914431e-02,  1.62318721e-02,  1.13105491e-01,\n",
       "          2.95976046e-02],\n",
       "        [ 9.79663879e-02, -6.01829886e-02, -1.16114412e-02,\n",
       "         -1.28001450e-02],\n",
       "        [-9.47436690e-03, -1.06430776e-01,  9.82953981e-02,\n",
       "         -6.52025342e-02],\n",
       "        [ 7.63550168e-03, -1.12071075e-01,  1.67355817e-02,\n",
       "         -1.26203552e-01],\n",
       "        [-4.72234003e-02,  1.56459678e-02,  8.22960883e-02,\n",
       "         -1.12655096e-01],\n",
       "        [-1.28305793e-01, -4.63211015e-02,  1.03621438e-01,\n",
       "          6.94533437e-02],\n",
       "        [ 2.03850493e-02,  9.47007775e-01,  2.64842901e-02,\n",
       "          6.12281589e-03],\n",
       "        [ 9.85031426e-01,  1.06399995e-03,  7.76252616e-03,\n",
       "          6.14205282e-03],\n",
       "        [ 1.38994702e-03,  9.51847911e-01,  9.21921106e-04,\n",
       "          4.58402112e-02],\n",
       "        [ 2.99433693e-02,  1.14852597e-03,  9.66397405e-01,\n",
       "          2.51071109e-03],\n",
       "        [ 7.03639491e-03,  1.12422900e-02,  1.45236799e-03,\n",
       "          9.80268896e-01],\n",
       "        [ 5.47018414e-03,  9.94436815e-03,  9.69081819e-01,\n",
       "          1.55035798e-02]], dtype=float32))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.load_config(config_path=\"cnn.yaml\")\n",
    "layer_name = \"arch.conv1d_tower.layers.0\"\n",
    "layer = get_layer(model, layer_name)\n",
    "pre_init_layer_weights = layer.weight.data.numpy().copy()\n",
    "pwms = md.to_kernel(motif_set, tensor=layer.weight.data, convert_to_pwm=False, divide_by_bg=False, motif_align=\"right\", kernel_align=\"right\")\n",
    "layer.weight = nn.Parameter(pwms)\n",
    "layer_weights = get_layer(model, layer_name).weight.data.numpy()\n",
    "pre_init_layer_weights[5].T, layer_weights[5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of kernels that are the same: 184\n"
     ]
    }
   ],
   "source": [
    "# Count the number of kernels that are the same before and after. Use close enough to account for floating point errors\n",
    "num_close = 0\n",
    "for i in range(len(pre_init_layer_weights)):\n",
    "    if np.allclose(pre_init_layer_weights[i], layer_weights[i]):\n",
    "        num_close += 1\n",
    "print(f\"Number of kernels that are the same: {num_close}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
